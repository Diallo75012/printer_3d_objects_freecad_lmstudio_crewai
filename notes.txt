## INSTALLS
pip install crewai['tools']
pip install openai
pip install groq
pip install langchain-groq
pip install langchain langchain_openai 
pip install -U duckduckgo-search

# get ultamaker
https://ultimaker.com/software/ultimaker-cura/
or wget https://github.com/Ultimaker/Cura/releases/download/5.7.0/UltiMaker-Cura-5.7.0-linux-X64.AppImage
sudo chmod +x UltiMaker-Cura-5.7.0-linux-X64.AppImage
./UltiMaker-Cura-5.7.0-linux-X64.AppImage --appimage-extract

# get Freecad
wget https://github.com/FreeCAD/FreeCAD-Bundle/releases/tag/0.21.2
sudo chmod +x FreeCAD_xxx-x86_64.AppImage
./FreeCAD_xxx-x86_64.AppImage --appimage-extract

### GROQ NOW SUPPORTS FUNCTION CALL WITH THE NEW TOOLS ABILITY
# source: https://console.groq.com/docs/tool-use#models
from groq import Groq
import os
import json

client = Groq(api_key = os.getenv('GROQ_API_KEY'))
MODEL = 'mixtral-8x7b-32768'


# Example dummy function hard coded to return the score of an NBA game
def get_game_score(team_name):
    """Get the current score for a given NBA game"""
    if "warriors" in team_name.lower():
        return json.dumps({"game_id": "401585601", "status": 'Final', "home_team": "Los Angeles Lakers", "home_team_score": 121, "away_team": "Golden State Warriors", "away_team_score": 128})
    elif "lakers" in team_name.lower():
        return json.dumps({"game_id": "401585601", "status": 'Final', "home_team": "Los Angeles Lakers", "home_team_score": 121, "away_team": "Golden State Warriors", "away_team_score": 128})
    elif "nuggets" in team_name.lower():
        return json.dumps({"game_id": "401585577", "status": 'Final', "home_team": "Miami Heat", "home_team_score": 88, "away_team": "Denver Nuggets", "away_team_score": 100})
    elif "heat" in team_name.lower():
        return json.dumps({"game_id": "401585577", "status": 'Final', "home_team": "Miami Heat", "home_team_score": 88, "away_team": "Denver Nuggets", "away_team_score": 100})
    else:
        return json.dumps({"team_name": team_name, "score": "unknown"})

def run_conversation(user_prompt):
    # Step 1: send the conversation and available functions to the model
    messages=[
        {
            "role": "system",
            "content": "You are a function calling LLM that uses the data extracted from the get_game_score function to answer questions around NBA game scores. Include the team and their opponent in your response."
        },
        {
            "role": "user",
            "content": user_prompt,
        }
    ]
    tools = [
        {
            "type": "function",
            "function": {
                "name": "get_game_score",
                "description": "Get the score for a given NBA game",
                "parameters": {
                    "type": "object",
                    "properties": {
                        "team_name": {
                            "type": "string",
                            "description": "The name of the NBA team (e.g. 'Golden State Warriors')",
                        }
                    },
                    "required": ["team_name"],
                },
            },
        }
    ]
    response = client.chat.completions.create(
        model=MODEL,
        messages=messages,
        tools=tools,
        tool_choice="auto",  
        max_tokens=4096
    )

    response_message = response.choices[0].message
    tool_calls = response_message.tool_calls
    # Step 2: check if the model wanted to call a function
    if tool_calls:
        # Step 3: call the function
        # Note: the JSON response may not always be valid; be sure to handle errors
        available_functions = {
            "get_game_score": get_game_score,
        }  # only one function in this example, but you can have multiple
        messages.append(response_message)  # extend conversation with assistant's reply
        # Step 4: send the info for each function call and function response to the model
        for tool_call in tool_calls:
            function_name = tool_call.function.name
            function_to_call = available_functions[function_name]
            function_args = json.loads(tool_call.function.arguments)
            function_response = function_to_call(
                team_name=function_args.get("team_name")
            )
            messages.append(
                {
                    "tool_call_id": tool_call.id,
                    "role": "tool",
                    "name": function_name,
                    "content": function_response,
                }
            )  # extend conversation with function response
        second_response = client.chat.completions.create(
            model=MODEL,
            messages=messages
        )  # get a new response from the model where it can see the function response
        return second_response.choices[0].message.content
    
user_prompt = "What was the score of the Warriors game?"
print(run_conversation(user_prompt))

# GROQ RATE LIMITS. Source: https://console.groq.com/docs/rate-limits

Header	                        Value	Notes
retry-after	                2	In seconds
x-ratelimit-limit-requests	14400	Always refers to Requests Per Day (RPD)
x-ratelimit-limit-tokens	18000	Always refers to Tokens Per Minute (TPM)
x-ratelimit-remaining-requests	14370	Always refers to Requests Per Day (RPD)
x-ratelimit-remaining-tokens	17997	Always refers to Tokens Per Minute (TPM)
x-ratelimit-reset-requests	2m59.56s	Always refers to Requests Per Day (RPD)
x-ratelimit-reset-tokens	7.66s	Always refers to Tokens Per Minute (TPM)

When the rate limit is reached we return a 429 Too Many Requests HTTP status code.
Note, retry-after is only set if you hit the rate limit and status code 429 is returned. The other headers are always included.

# GROQ new model like GTP4 almost
llama3-70b-8192

# mount disk E:/ to linux /mnt/e
sudo mkdir /mnt/e
sudo vmhgfs-fuse .host:/E /mnt/e -o allow_other

# LMSTUDIO is to be installed
we have our own in the detection project we will use that one

# if needed to add a vision llm we might need to convert the '.stl' file to  a '.png' file
pip install vtk
import vtk

def stl_to_png(stl_file, output_image):
    # Create a reader for the STL file
    reader = vtk.vtkSTLReader()
    reader.SetFileName(stl_file)
    
    # Create a mapper for the STL data
    mapper = vtk.vtkPolyDataMapper()
    mapper.SetInputConnection(reader.GetOutputPort())
    
    # Create an actor to represent the STL model
    actor = vtk.vtkActor()
    actor.SetMapper(mapper)
    
    # Set up the renderer and render window
    renderer = vtk.vtkRenderer()
    renderWindow = vtk.vtkRenderWindow()
    renderWindow.AddRenderer(renderer)
    renderWindow.SetOffScreenRendering(1)  # Enable off-screen rendering
    
    # Create a render window interactor (not strictly necessary in this case)
    renderWindowInteractor = vtk.vtkRenderWindowInteractor()
    renderWindowInteractor.SetRenderWindow(renderWindow)
    
    # Add the actor to the scene
    renderer.AddActor(actor)
    renderer.SetBackground(1, 1, 1)  # Set background to white
    
    # Render the STL model
    renderWindow.Render()
    
    # Take a screenshot
    windowToImageFilter = vtk.vtkWindowToImageFilter()
    windowToImageFilter.SetInput(renderWindow)
    windowToImageFilter.Update()
    
    # Write the screenshot to a file
    writer = vtk.vtkPNGWriter()
    writer.SetFileName(output_image)
    writer.SetInputConnection(windowToImageFilter.GetOutputPort())
    writer.Write()

# Example usage
stl_file = 'path/to/your/model.stl'
output_image = 'path/to/your/output.png'
stl_to_png(stl_file, output_image)

# prompt used:
I need a 3D cube to be drawn using Freecad Python console and then slicing layers to be created so that I can 3D print the cube which has 10cm sides.

# check if files present:
ll freecad_script/ agent_stl/ stl/ gcode/

### CREWAI
## CrewAI Create Custom Tool
# put your function logic inside this wrapper
from crewai_tools import BaseTool

class MyCustomTool(BaseTool):
    name: str = "Name of my tool"
    description: str = "What this tool does. It's vital for effective utilization."

    def _run(self, argument: str) -> str:
        # Your tool's logic here
        return "Tool's result"

OR use tool decorator by just addint name of the tool in decorator:
from crewai_tools import tool

@tool("Tool Name")
def my_simple_tool(question: str) -> str:
    """Tool description for clarity."""
    # Tool logic here
    return "Tool output"

# get rid of crewai team work cache to restart fresh
sudo rm -rf /printer_3d_venv/lib/python3.10/site-packages/crewai/__pycache__
sudo rm -rf /printer_3d_venv/lib/python3.10/site-packages/crewai_tools/__pycache__


### Freecad
# open Freecad Python console:
AppRun freecadcmd

# execute script in the console command:
exec(open("/<path_to_script>Test1.py").read())


### Issues

- when process is sequential: max_iter limit is reached the agent team stops working so task is not proceeding from where it has stopped. No grace period.
- when process is hirarchical: the manager is not very clever and doesn't really manage well the co-worker team, I believe that the manager should have also set of variables like the agents with goals and what to do when something occurs. The manager also doesn't follow the workflow correctly and use random agents when the output of one is not yet produced and another agent depend on it (prompt issues?? not sure but have tested different ways, it seems to have issues: case of 7B parameters LLM, maybe with GPT4 would be more clever).
- agents: sometimes they just ignore the tools available and do the job themselves. so sometimes never use the tools available or sometimes using the tools but very late in the process after a while.
- Allucinations: Agents also sometimes don't seems to find tool and invent tool names taht don't exist. Agents lying when saying they used tool and did find the file output at the right location, when in reality no file have been output... this is a problem as the next agent start working and throuws an error and this becomes and error loop.


# Install slic3r for layer slicing as ultimaker asking to have a 3d printer to connect to it
sudo apt update
sudo apt install slic3r -y
command to slice:
slic3r --layer-height 0.2 --fill-density 20% --output /home/creditizens/printer_3d_llm_agents/gcode/cube.gcode /home/creditizens/printer_3d_llm_agents/stl/cube.stl
outputs:
=> Infilling layers
=> Processing triangulated mesh
=> Preparing infill
=> Generating skirt
=> Generating brim
=> Exporting G-code to /home/creditizens/printer_3d_llm_agents/gcode/cube.gcode
Done. Process took 0 minutes and 0.096 seconds
Filament required: 862.5mm (6.1cm3)

















